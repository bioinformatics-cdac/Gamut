{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is Gamut \u00b6 GAMUT - Platform for addressing high throughput analysis and management of variant data produced by Next Generation Sequencing techniques. Developed by : High Performance Computing - Medical & Bioinformatics Applications Group (HPC-M&BA) at Center for Development of Advanced Computing (C-DAC), Pune, India. For more details click here Features \u00b6 Accelerated Search : Speed and Optimization are key attributes for any search, Gamut enables these features for search across large genomic databases. Graphical Output : Graphical output displays the results in different graphical formats like bar and pie charts. Big data Solution : MongoDB is used at backend for support as a big data database solution for life sciences data. Variant Comparison : Efficient analysis of Single Nucleotide Polymorphisms (SNPs) across genomic samples enable in deciphering the relationship between genotype and phenotype. The core principle behind SNP comparison is to arrive at a probable list of variants that can differentiate two sets of data (populations). Such SNPs have direct applications in array design, genotype imputation and in cataloging of variants in regions of interest. 1000 Genome data : The International Genome Sample Resource (IGSR) was established to ensure the ongoing usability of data generated by the 1000 Genomes Project.1000 genomes have provided ~85 million genetic variants (SNPs) that have frequencies of at least 1% in the populations studied (1000 Genomes Project Consortium et al. 2015). The data provides a glimpse of underlying similarities and variations which can be used for genetic differentiation (Enard et al. 2014). GitHub URL \u00b6 https://github.com/bioinformatics-cdac/gamut Sample Input Data \u00b6 Sample Input data is provided with Gamut installer. Eight individuals from 1000 Genome Data belonging to different populations have been used as sample data. A sample VCF file has been generated for the 8 individuals using the following genomic coordinates Chromosome Start End 1 10505 999999 2 10180 999817 3 60069 999979 4 10202 999992 5 10043 999969 6 63854 999962 7 14808 999995 8 11740 1000000 9 10327 999972 10 60494 999977 11 73015 999999 12 60181 999935 16 60086 999963 17 52 999996 18 10644 999993 19 60842 999975 20 60343 1000010 21 9411239 9999932 X 60026 999973 Try With PWD \u00b6","title":"Overview"},{"location":"#what-is-gamut","text":"GAMUT - Platform for addressing high throughput analysis and management of variant data produced by Next Generation Sequencing techniques. Developed by : High Performance Computing - Medical & Bioinformatics Applications Group (HPC-M&BA) at Center for Development of Advanced Computing (C-DAC), Pune, India. For more details click here","title":"What is Gamut"},{"location":"#features","text":"Accelerated Search : Speed and Optimization are key attributes for any search, Gamut enables these features for search across large genomic databases. Graphical Output : Graphical output displays the results in different graphical formats like bar and pie charts. Big data Solution : MongoDB is used at backend for support as a big data database solution for life sciences data. Variant Comparison : Efficient analysis of Single Nucleotide Polymorphisms (SNPs) across genomic samples enable in deciphering the relationship between genotype and phenotype. The core principle behind SNP comparison is to arrive at a probable list of variants that can differentiate two sets of data (populations). Such SNPs have direct applications in array design, genotype imputation and in cataloging of variants in regions of interest. 1000 Genome data : The International Genome Sample Resource (IGSR) was established to ensure the ongoing usability of data generated by the 1000 Genomes Project.1000 genomes have provided ~85 million genetic variants (SNPs) that have frequencies of at least 1% in the populations studied (1000 Genomes Project Consortium et al. 2015). The data provides a glimpse of underlying similarities and variations which can be used for genetic differentiation (Enard et al. 2014).","title":"Features"},{"location":"#github-url","text":"https://github.com/bioinformatics-cdac/gamut","title":"GitHub URL"},{"location":"#sample-input-data","text":"Sample Input data is provided with Gamut installer. Eight individuals from 1000 Genome Data belonging to different populations have been used as sample data. A sample VCF file has been generated for the 8 individuals using the following genomic coordinates Chromosome Start End 1 10505 999999 2 10180 999817 3 60069 999979 4 10202 999992 5 10043 999969 6 63854 999962 7 14808 999995 8 11740 1000000 9 10327 999972 10 60494 999977 11 73015 999999 12 60181 999935 16 60086 999963 17 52 999996 18 10644 999993 19 60842 999975 20 60343 1000010 21 9411239 9999932 X 60026 999973","title":"Sample Input Data"},{"location":"#try-with-pwd","text":"","title":"Try With PWD"},{"location":"install/build-manual/","text":"Step 1: git clone https://github.com/bioinformatics-cdac/gamut Step 2: cd gamut && mvn clean install Step 3: Install Mongo DB Step 4: copy .snp folder at /home/ Step 5: Make dir /home/gamut/user/upload Step 6: Download WildFly web server https://www.wildfly.org/downloads/ Step 7 : Copy Gamut war file in to Wildfly/standalone/deployments/ Step 8: Modify standalone.xml file with following configuration Undertow configuration","title":"Manual Installation (Suggested for advanced users)"},{"location":"install/run-docker-compose/","text":"How to Use the Gamut from DockerHub \u00b6 Pre-requisites \u00b6 Docker Engine and Docker Compose installed either locally or remote, depending on available setup. Docker Installation Install Docker https://docs.docker.com/get-docker Install Docker Compose https://docs.docker.com/compose/install/ Check docker run docker ps Step 1: Make clone image of Gamut \u00b6 git clone https://github.com/bioinformatics-cdac/gamut Step 2: Change the directory \u00b6 cd gamut Step 3: Run Gamut docker image \u00b6 docker-compose up -d wait for 2 minutes for loading of sample data Step 4: Open url in browser \u00b6 http://localhost:8080/ Screenshot \u00b6 Step 5: Stop docker container \u00b6 Once analysis is completed using either sample or user defined datasets it is advised to stop the docker containers docker-compose down","title":"Docker Compose"},{"location":"install/run-docker-compose/#how-to-use-the-gamut-from-dockerhub","text":"","title":"How to Use the Gamut from DockerHub"},{"location":"install/run-docker-compose/#pre-requisites","text":"Docker Engine and Docker Compose installed either locally or remote, depending on available setup. Docker Installation Install Docker https://docs.docker.com/get-docker Install Docker Compose https://docs.docker.com/compose/install/ Check docker run docker ps","title":"Pre-requisites"},{"location":"install/run-docker-compose/#step-1-make-clone-image-of-gamut","text":"git clone https://github.com/bioinformatics-cdac/gamut","title":"Step 1: Make clone image of Gamut"},{"location":"install/run-docker-compose/#step-2-change-the-directory","text":"cd gamut","title":"Step 2:  Change the directory"},{"location":"install/run-docker-compose/#step-3-run-gamut-docker-image","text":"docker-compose up -d wait for 2 minutes for loading of sample data","title":"Step 3:  Run Gamut docker image"},{"location":"install/run-docker-compose/#step-4-open-url-in-browser","text":"http://localhost:8080/","title":"Step 4:  Open url in browser"},{"location":"install/run-docker-compose/#screenshot","text":"","title":"Screenshot"},{"location":"install/run-docker-compose/#step-5-stop-docker-container","text":"Once analysis is completed using either sample or user defined datasets it is advised to stop the docker containers docker-compose down","title":"Step 5:  Stop docker container"},{"location":"install/run-from-source/","text":"How to Use the Gamut from source \u00b6 Pre-requisites \u00b6 Docker Engine and Docker Compose installed either locally or remote, depending on available setup. Docker Installation Install Docker https://docs.docker.com/get-docker Install Docker Compose https://docs.docker.com/compose/install/ Check docker run docker ps Step 1: Make clone image of Gamut \u00b6 git clone https://github.com/bioinformatics-cdac/gamut Step 2: Change the directory \u00b6 cd gamut Step 3: Make maven clean install \u00b6 mvn clean install Step 4: Build Gamut docker image \u00b6 docker build -t bioinformaticscdac/gamut . Step 5: Run Gamut docker image \u00b6 docker-compose up -d wait for 2 minutes for load sample data Step 6: Open url in browser \u00b6 http://localhost:8080/ Screenshot \u00b6 Step 5: Stop docker container \u00b6 Once analysis is completed using either sample or user defined datasets it is advised to stop the docker containers docker-compose down","title":"Build from source"},{"location":"install/run-from-source/#how-to-use-the-gamut-from-source","text":"","title":"How to Use the Gamut from source"},{"location":"install/run-from-source/#pre-requisites","text":"Docker Engine and Docker Compose installed either locally or remote, depending on available setup. Docker Installation Install Docker https://docs.docker.com/get-docker Install Docker Compose https://docs.docker.com/compose/install/ Check docker run docker ps","title":"Pre-requisites"},{"location":"install/run-from-source/#step-1-make-clone-image-of-gamut","text":"git clone https://github.com/bioinformatics-cdac/gamut","title":"Step 1: Make clone image of Gamut"},{"location":"install/run-from-source/#step-2-change-the-directory","text":"cd gamut","title":"Step 2:   Change the directory"},{"location":"install/run-from-source/#step-3-make-maven-clean-install","text":"mvn clean install","title":"Step 3:  Make maven clean install"},{"location":"install/run-from-source/#step-4-build-gamut-docker-image","text":"docker build -t bioinformaticscdac/gamut .","title":"Step 4:  Build Gamut docker image"},{"location":"install/run-from-source/#step-5-run-gamut-docker-image","text":"docker-compose up -d wait for 2 minutes for load sample data","title":"Step 5:  Run Gamut docker image"},{"location":"install/run-from-source/#step-6-open-url-in-browser","text":"http://localhost:8080/","title":"Step 6:  Open url in browser"},{"location":"install/run-from-source/#screenshot","text":"","title":"Screenshot"},{"location":"install/run-from-source/#step-5-stop-docker-container","text":"Once analysis is completed using either sample or user defined datasets it is advised to stop the docker containers docker-compose down","title":"Step 5:  Stop docker container"},{"location":"usage/use/","text":"How to use Gamut \u00b6 Basic Search \u00b6 - Select individuals to be used as Set-I and Set-II populations - Select genomic coordinates of any chromosome of interest(Enter Chromosome position Start and End) - Click Search button - Tabular Output Upload of user-defined datasets \u00b6 Upload GTF and VCF population files - Please note the time for upload and storing into MongoDB depends on the file size - Once upload is completed, the data is ready for query Performance of GAMUT for data upload and retrieval (*using Ubuntu 18.04.5 LTS server with AMD EPYC 7452 32-Core Processor with 128GB RAM) \u00b6","title":"Usage"},{"location":"usage/use/#how-to-use-gamut","text":"","title":"How to use Gamut"},{"location":"usage/use/#basic-search","text":"- Select individuals to be used as Set-I and Set-II populations - Select genomic coordinates of any chromosome of interest(Enter Chromosome position Start and End) - Click Search button - Tabular Output","title":"Basic Search"},{"location":"usage/use/#upload-of-user-defined-datasets","text":"Upload GTF and VCF population files - Please note the time for upload and storing into MongoDB depends on the file size - Once upload is completed, the data is ready for query","title":"Upload of user-defined datasets"},{"location":"usage/use/#performance-of-gamut-for-data-upload-and-retrieval-using-ubuntu-18045-lts-server-with-amd-epyc-7452-32-core-processor-with-128gb-ram","text":"","title":"Performance of GAMUT for data upload and retrieval (*using Ubuntu 18.04.5 LTS server with AMD EPYC 7452 32-Core Processor with 128GB RAM)"}]}